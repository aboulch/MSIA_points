{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MSIA - Points - 3 - Surface reconstruction from point clouds\n",
        "\n",
        "In this practical session, we will:\n",
        "- load an visualize a point cloud\n",
        "- design a simple RANSAC algorithm for plane fitting\n",
        "- improve this approach using normal estimation"
      ],
      "metadata": {
        "id": "GJy8u4gu1ukp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook setup\n",
        "\n",
        "For point cloud loading we use [trimesh](https://trimesh.org/) which is one of the many python libraries that can be used for point cloud processing. As it is not available on Colab, we first install it."
      ],
      "metadata": {
        "id": "DP3Z-7BaEZeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the missing package\n",
        "!pip install trimesh"
      ],
      "metadata": {
        "id": "mBM1gJ6oZn11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we download the point cloud we will work with. The point cloud can be directly donwloaded from the course [github]( https://github.com/aboulch/MSIA_points) or using the following command."
      ],
      "metadata": {
        "id": "js4h2nlCE3cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load a points cloud\n",
        "!wget https://github.com/aboulch/MSIA_points/releases/download/v0.0.0/mesh_a003a6585e.ply"
      ],
      "metadata": {
        "id": "QbHbHqdQf4c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we import the libraries useful for this practical session.\n",
        "The whole practical session will be managed with numpy."
      ],
      "metadata": {
        "id": "jPS072KNFObm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxhZd2kb1oBf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "import trimesh\n",
        "import math\n",
        "import plotly.graph_objects as go # for visualization\n",
        "from scipy.spatial import KDTree"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading / decimating and visualizing point clouds\n",
        "\n",
        "In this section we define the functions needed for preparing the point cloud.\n",
        "\n",
        "First, we give a convenient function to visualize the point clouds using the Plotly library.\n",
        "It takes as input a point cloud (`pts`) and colors (`cls`, with values in $[0,1]$).\n",
        "The function creates a Figure and draw the points with Scatter3D, there are several options to the function (see Plotly documentation), one of the most useful is the marker size (apparent size of the points)."
      ],
      "metadata": {
        "id": "LER_Ssj-Nz1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def point_cloud_visu(pts, cls=None):\n",
        "\n",
        "  fig = go.Figure(\n",
        "      data=[\n",
        "          go.Scatter3d(\n",
        "              x=pts[:,0], y=pts[:,1], z=pts[:,2],\n",
        "              mode='markers',\n",
        "              marker=dict(size=3, color=cls)\n",
        "          )\n",
        "      ],\n",
        "      layout=dict(\n",
        "          scene=dict(\n",
        "              xaxis=dict(visible=False),\n",
        "              yaxis=dict(visible=False),\n",
        "              zaxis=dict(visible=False),\n",
        "              aspectmode=\"data\", #this string can be 'data', 'cube', 'auto', 'manual'\n",
        "              #a custom aspectratio is defined as follows:\n",
        "              aspectratio=dict(x=1, y=1, z=0.95)\n",
        "          )\n",
        "      )\n",
        "  )\n",
        "  fig.show()\n"
      ],
      "metadata": {
        "id": "nRc25-YkO6oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Point decimation via voxelization or random sampling\n",
        "\n",
        "The proposed point cloud is too large to work with it efficiently.\n",
        "First, we will decimate to reduce its size.\n",
        "Two very common decimation procedures are *random sampling* and *voxel decimation*.\n",
        "\n",
        "**Question:** fill `load_and_decimate_room_pc_rand` which selects `n` points randomly in the point cloud\n",
        "\n"
      ],
      "metadata": {
        "id": "BQLExd4EPXOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_decimate_room_pc_rand(num_pts=10000):\n",
        "  \"\"\"\n",
        "  function: load and randomly subsample a point cloud\n",
        "  input: number of points\n",
        "  output: points and normals\n",
        "  \"\"\"\n",
        "\n",
        "  pcd = trimesh.load(\"mesh_a003a6585e.ply\")\n",
        "  pts = pcd.vertices\n",
        "  cols = pcd.visual.vertex_colors\n",
        "\n",
        "  ### Fill this part with decimation\n",
        "  ###\n",
        "\n",
        "  # to be removed once the function is implmented\n",
        "  pts = pts[:1000]\n",
        "  cols = cols[:1000]\n",
        "\n",
        "  return pts, cols[:,:3]"
      ],
      "metadata": {
        "id": "9S4WLn9MPib8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Question:** fill `load_and_decimate_room_pc_voxels` which discretize the point cloud on a 3D grid of size `voxel_size` and keep one point per voxel."
      ],
      "metadata": {
        "id": "FUvmLKLWPxl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_decimate_room_pc_voxels(voxel_size=0.10):\n",
        "  \"\"\"\n",
        "  function: load and subsample a point cloud (one point per voxel)\n",
        "  input: number of points\n",
        "  output: points and normals\n",
        "  \"\"\"\n",
        "  # Hint: it is possible to \"inflate\" the coordinates of the point cloud such\n",
        "  # that voxel size correspond to 1, then take integral part of the coordinates\n",
        "  # and select one unique point in each voxel (np.unique)\n",
        "\n",
        "  pcd = trimesh.load(\"mesh_a003a6585e.ply\")\n",
        "  pts = pcd.vertices\n",
        "  cols = pcd.visual.vertex_colors\n",
        "\n",
        "  ### Fill this part with decimation\n",
        "  ###\n",
        "\n",
        "  # to be removed once the function is implmented\n",
        "  pts = pts[:1000]\n",
        "  cols = cols[:1000]\n",
        "\n",
        "  return pts, cols[:,:3]"
      ],
      "metadata": {
        "id": "uW_8GYtAPjRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now load the point cloud, decimate it and visualize it.\n",
        "For loading we use Open3d, a 3D processing library (this library does not only load points, it contains many algorithms, beyond the scope of this course).\n",
        "\n",
        "**Question:** Compare random decimation and voxel decimation."
      ],
      "metadata": {
        "id": "k35Cfq3lRpVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the points decimated with random sampling\n",
        "pts_rand, cols_rand = load_and_decimate_room_pc_rand()\n",
        "\n",
        "# load the points decimated using voxel grid\n",
        "pts_vox, cols_vox = load_and_decimate_room_pc_voxels()\n",
        "\n",
        "# translate one the point cloud for visu, side by side\n",
        "pts_vox[:,0] += 8\n",
        "\n",
        "# assemble the points\n",
        "pts_visu = np.concatenate([pts_rand, pts_vox], axis=0)\n",
        "cols_visu = np.concatenate([cols_rand, cols_vox], axis=0)\n",
        "point_cloud_visu(pts_visu, cols_visu)\n"
      ],
      "metadata": {
        "id": "y02w0Gqt13HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normal estimation for point cloud\n",
        "\n",
        "In this section, we will implement a normal estimator for point clouds.\n",
        "The objective is to estimate a unit vector $\\mathbf{n}$ at each point $\\mathbf{p}$.\n",
        "\n",
        "To do so, we will implement the most common normal estimator: the local plane regression from [1].\n",
        "As shown in the course, given a set of point $\\mathcal{N}$, we compute the covariance matrix, diagonalize it and find the eigen vector corresponding to the lowest eigen vector.\n",
        "\n",
        "**Question:** complete the function `plane_fitting_pca` to compute the regression plane for the input point cloud `pts`.\n",
        "\n",
        "*Note:* we want it to work with batches, i.e., compute the matrices for several point clouds at once. This saves the use of slow loop later.\n"
      ],
      "metadata": {
        "id": "do2pVjO6PK_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def covariance_matrix(pts):\n",
        "  # input: point cloud [N 3]\n",
        "  # output: 3x3 matrix covariance matrix\n",
        "  assert(len(pts.shape)==2)\n",
        "\n",
        "  ### Fill this part\n",
        "  ###\n",
        "\n",
        "  # to be removed\n",
        "  cov = np.eye(3)\n",
        "\n",
        "  return cov\n",
        "\n",
        "# create a random point cloud on a plane\n",
        "pts = np.random.rand(1000,3)\n",
        "pts[:,0] *= 2\n",
        "pts[:,1] *= 0.5\n",
        "pts[:,2] *= 0\n",
        "\n",
        "# visualize the point cloud\n",
        "point_cloud_visu(pts)\n",
        "\n",
        "# compare our method with the numpy function (should give the same result)\n",
        "print(\"Our method that works with batches:\")\n",
        "print(covariance_matrix(pts))\n",
        "print(\"Numpy version, not batched\")\n",
        "print(np.cov(pts.T))"
      ],
      "metadata": {
        "id": "0V7-GuWlhIAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plane equation is given by $ax + by + cz + d = 0$.\n",
        "\n",
        "**Question:** complete the function to fit a plane by PCA:\n",
        "The input is the point cloud `pts` (size [B,N,3]), the output is the plane parameters $(a,b,c,d)$ size [B,4].\n",
        "The batch B is optional\n",
        "\n",
        "* compute the covariance matrix\n",
        "* diagonalize the matrix\n",
        "* find the lowest eigen value\n",
        "* find the corresponding eigen vector\n",
        "* normalize it\n",
        "* compute the $d$ parameter of the plane equation.\n"
      ],
      "metadata": {
        "id": "4tz2N377l0jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plane_fitting_pca(pts_):\n",
        "  assert(len(pts.shape)==2)\n",
        "\n",
        "  ###################\n",
        "  ### Fill the part\n",
        "  # note: eigen values and vectors can be computed using numpy functions\n",
        "  # covariance matrix\n",
        "  # diagonalize the covariance matrix\n",
        "  # find the smallest eigenvalue\n",
        "  # find the corresponding eigen vector (hint, use np.take_along_axis)\n",
        "  # normalize it\n",
        "  # compute the d parameter of the plane equation\n",
        "  # create the plane equation (a b c d)\n",
        "  ###################\n",
        "\n",
        "  # to be removed\n",
        "  plane = np.array([[1,0,0,0]])\n",
        "\n",
        "  # return the plane equation\n",
        "  return plane\n",
        "\n",
        "# create an horizontal plane\n",
        "pts = np.random.rand(1000,3)\n",
        "pts[:,0] *= 2\n",
        "pts[:,1] *= 0.5\n",
        "pts[:,2] *= 0\n",
        "\n",
        "print(\"Plane equation (should be [0,0,1,0] or [0,0,-1,0]):\")\n",
        "print(plane_fitting_pca(pts))"
      ],
      "metadata": {
        "id": "B3U12ZhOPKBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have plane fitting function, we can use it compute the normals in a point cloud.\n",
        "To do so, for each point, we need to compute neighborhood (small point cloud) on which we will fit a plane.\n",
        "\n",
        "For efficiency, we will use a [KDTree](https://en.wikipedia.org/wiki/K-d_tree), which is an efficient space partitioning data structure. Which allows the compute the $k$ nearest neighbors with complexity $O(k \\log n)$ ($n$ being the size of the point cloud) on average.\n",
        "\n",
        "We will use the [KDTree class from Scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html).\n",
        "\n",
        "**Question:** complete the function for normal estimation.\n"
      ],
      "metadata": {
        "id": "tezrdmo2oAEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate the normals\n",
        "def normal_estimation(pts, k):\n",
        "  \"\"\"\n",
        "  input:\n",
        "    - pts, point cloud (size [N, 3])\n",
        "    - k, size of the neighborhoods for normal regression\n",
        "  output:\n",
        "    - normals (size [N,3])\n",
        "  \"\"\"\n",
        "\n",
        "  ##################\n",
        "  ## Fill this part\n",
        "  # compute the neighbors for each plane with a KDTree\n",
        "  # compute the normals by fitting a plane\n",
        "  ###################\n",
        "\n",
        "  # to be removed\n",
        "  normals = np.zeros_like(pts)\n",
        "  normals[:,0] = 1\n",
        "\n",
        "  return normals\n",
        "\n",
        "\n",
        "# load the point cloud\n",
        "pts, cols = load_and_decimate_room_pc_voxels()\n",
        "\n",
        "# compute the normals\n",
        "normals = normal_estimation(pts, k=16)\n",
        "\n",
        "# compute colors from normals\n",
        "cols_normals = ((normals +1)/2 * 255).astype(np.uint8)\n",
        "\n",
        "# visu\n",
        "point_cloud_visu(pts, cols_normals)"
      ],
      "metadata": {
        "id": "79VzNqtEuKXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Sample Consensus (RANSAC)\n",
        "\n",
        "We now enter the core of the practical session.\n",
        "As seen during the course, RANSAC is a quite simple algorithm that can be summarized as:\n",
        "```\n",
        "INIT: points, best_hypothesis, best_inliers\n",
        "REPEAT(MAX_ITER):\n",
        "  GENERATE plane_hypothesis(points)\n",
        "  COMPUTE inliers(points, plane_hypothesis)\n",
        "  COMPARE inliers > best_inliers:\n",
        "    ASSIGN best_hypothesis <- plane_hypothtesis\n",
        "    ASSIGN best_inliers <- inliers\n",
        "```\n",
        "In this part, the proposed method is inspired from [2], which uses additional component to make it faster and more general.\n"
      ],
      "metadata": {
        "id": "I4JYyucPrfvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plane hypothesis using three points\n",
        "\n",
        "A first way to define a plane is to pick three points and compute the regression plane for these three points.\n",
        "\n",
        "**Question:** fill `plane_from_three_points` which compute the plane equation (size [4]) associated with three points randomly selected in the point cloud.\n",
        "\n",
        "*Note:* even if not the most efficient way to do, it is easier to reuse the function to compute normals.\n",
        "\n",
        "Then, we need to compute the inliers for the selected plane $\\mathcal{P}$. These inliers are the points of the point cloud $\\mathbf{P}$ such that:\n",
        "$$ \\mathbf{I}(\\mathbf{P}, \\mathcal{P}, \\delta) = \\{ \\mathbf{p} \\in \\mathbf{P} ,\\: \\text{s.t.} \\: d(\\mathbf{p}, \\mathcal{P}) < \\delta \\}$$\n",
        " where $d$ is the Euclidean distance and $\\delta$ a threshold.\n",
        "\n",
        "**Question:** fill `get_inliers_in_plane` the function that computes the inlier given a plane and a point cloud."
      ],
      "metadata": {
        "id": "SdGX5E4D0Epp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plane_from_three_points(pts):\n",
        "  \"\"\"\n",
        "  Function: compute the plane equation from 3 points randomly selected in the\n",
        "  point cloud\n",
        "  \"\"\"\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  plane = np.array([[1,0,0,0]])\n",
        "\n",
        "  plane = plane[0]\n",
        "  return plane\n",
        "\n",
        "def get_inliers_in_plane(pts, plane, distance_threshold):\n",
        "  \"\"\"\n",
        "  Function: compute the points close to a plane (up to a threshold)\n",
        "  input:\n",
        "    - pts\n",
        "    - plane\n",
        "  output:\n",
        "    - mask (pts.shape[0],) of booleans: true if inliers, false if outliers\n",
        "  \"\"\"\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  mask = np.ones(pts.shape[0], dtype=bool)\n",
        "\n",
        "  return mask\n",
        "\n",
        "# load the point cloud\n",
        "pts, cols = load_and_decimate_room_pc_voxels()\n",
        "\n",
        "# estimate a random plane\n",
        "plane = plane_from_three_points(pts)\n",
        "\n",
        "# get the inliers\n",
        "mask = get_inliers_in_plane(pts, plane, 0.1)\n",
        "\n",
        "# give red color to the inliers\n",
        "cols_plane_tmp = cols[mask].copy()\n",
        "cols_plane_tmp *= 0\n",
        "cols_plane_tmp[:,0] = 255\n",
        "cols_plane = cols.copy()\n",
        "cols_plane[mask] = cols_plane_tmp\n",
        "\n",
        "# display the point cloud\n",
        "point_cloud_visu(pts,cols_plane)"
      ],
      "metadata": {
        "id": "IryKS9jjQrlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to compute the maximal number of iterations (number of plane hypothesis to compute) needed to find a plane containing a minimal number of points.\n",
        "\n",
        "As a reminder from the course.\n",
        "\n",
        "The probablity of picking three inlier points in the point cloud is:\n",
        "$$P(n) = \\left( \\frac{n}{N} \\right)^3$$\n",
        "where $n$ is the minimal number of point to be considered a valid shape, and $N$ the size of the point cloud.\n",
        "\n",
        "Then, propability that the plane is not an inlier is:\n",
        "$$ 1 - \\left( \\frac{n}{N} \\right)^3, $$\n",
        "the probability that after $s$ attempts we do not get one inlier plane is\n",
        "$$ \\left(1 - \\left( \\frac{n}{N} \\right)^3 \\right)^s,$$\n",
        "and the probability that we get and inlier plane:\n",
        "$$ P(n,s) = 1 - \\left(1 - \\left( \\frac{n}{N} \\right)^3 \\right)^s.$$\n",
        "\n",
        "We search $T$ such that the probability of success if greater than a given probability $p_t$:\n",
        "$$ P(n,T) \\geq p_t .$$\n",
        "\n",
        "**Question:** fill the function `get_max_num_iter` which compute the $T$ value."
      ],
      "metadata": {
        "id": "6nU506hfKStH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_num_iter(min_pts, num_pts, proba_of_success):\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  T = 10\n",
        "\n",
        "  return int(T) + 1"
      ],
      "metadata": {
        "id": "biUSzWtI92C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have all the ingredients to search for the best plane using the RANSAC algorithm.\n",
        "\n",
        "**Question:** fill the function `search_one_plane` that attempts to find the best plane."
      ],
      "metadata": {
        "id": "hEEpe2jYNLpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_one_plane(pts, normals, min_pts, plane_threshold, proba_of_success):\n",
        "  \"\"\"\n",
        "  Function: search the best plane by iteratively selecting plane hypotheses and\n",
        "  retain the plane with the most inliers\n",
        "  - input:\n",
        "    - pts: the point cloud\n",
        "    - normals: not used for this function\n",
        "    - min_pts: minimal number of points in a valid shape\n",
        "    - plane_threshold: the distance threshold for plane hypothesis\n",
        "  - output:\n",
        "    - plane_equation: equation of the plane\n",
        "    - inlier_mask: boolean mask for the inliers\n",
        "  \"\"\"\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "  # compute max iters\n",
        "  # iterate over iters\n",
        "  # memorize the best plane\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  cur_plane_equation = np.array([1,0,0,0])\n",
        "  cur_plane_mask = np.ones(pts.shape[0], dtype=bool)\n",
        "\n",
        "  return cur_plane_equation, cur_plane_mask\n",
        "\n",
        "# load the points\n",
        "pts, cols = load_and_decimate_room_pc_voxels()\n",
        "\n",
        "# search for the best plane\n",
        "plane_equation, plane_mask = search_one_plane(pts, None,\n",
        "      min_pts=500,\n",
        "      plane_threshold=0.05,\n",
        "      proba_of_success=0.9)\n",
        "\n",
        "# give red color to the inliers\n",
        "cols_plane_tmp = cols[plane_mask].copy()\n",
        "cols_plane_tmp *= 0\n",
        "cols_plane_tmp[:,0] = 255\n",
        "cols_plane = cols.copy()\n",
        "cols_plane[plane_mask] = cols_plane_tmp\n",
        "\n",
        "# display the point cloud\n",
        "point_cloud_visu(pts,cols_plane)"
      ],
      "metadata": {
        "id": "_T1lWsYqmyKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plane hypothesis using one point and normal\n",
        "\n",
        "A second way to define a plane is to pick one plane with its associated normal.\n",
        "\n",
        "**Question:** fill `plane_from_one_point_normal` which compute the plane equation (size [4]) associated with one point randomly selected in the point cloud.\n"
      ],
      "metadata": {
        "id": "5d2ULT4ZN162"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plane_from_one_point_normal(pts, normals):\n",
        "  \"\"\"\n",
        "  Function: compute the plane equation from 3 points randomly selected in the\n",
        "  point cloud\n",
        "  \"\"\"\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  plane = np.array([1,0,0,0])\n",
        "  return plane"
      ],
      "metadata": {
        "id": "i_1hvTevQgaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we need to compute the inliers for the selected plane $\\mathcal{P}$.\n",
        "Here, we now suppose the points to have an associated normal.\n",
        "Thus, inliers should have a normal aligned with the plane normal (up to orientation).\n",
        "These inliers are the points of the point cloud $\\mathbf{P}$ such that:\n",
        "$$ \\mathbf{I}(\\mathbf{P}, \\mathcal{P}, \\delta) = \\{ \\mathbf{p} \\in \\mathbf{P} ,\\: \\text{s.t.} \\: d(\\mathbf{p}, \\mathcal{P}) < \\delta \\: \\textbf{and} \\: |<\\mathbf{n}(\\mathcal{P}), \\mathbf{n} >| < \\gamma \\}$$\n",
        " where $d$ is the Euclidean distance, $\\delta$ a distance threshold, $<.,.>$ is the inner product and $\\gamma$ an orientation threshold.\n",
        "\n",
        "**Question:** fill `get_inliers_in_plane_normals` this function only compute the orientation part of the inlier retrieval (we already coded the distance part in ).\n"
      ],
      "metadata": {
        "id": "eZKsA4AeQlZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inliers_in_plane_normals(normals, plane, orient_threshold):\n",
        "  \"\"\"\n",
        "  Function: get the points that have the same normal as the plane (up to a threshold)\n",
        "  input:\n",
        "    - pts\n",
        "    - plane\n",
        "    - orient_threshold\n",
        "  output:\n",
        "    - mask (pts.shape[0],) of booleans: true if inliers, false if outliers\n",
        "  \"\"\"\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  mask_normals = np.ones(normals.shape[0], dtype=bool)\n",
        "\n",
        "  return mask_normals\n",
        "\n",
        "# load the point cloud\n",
        "pts, cols = load_and_decimate_room_pc_voxels()\n",
        "\n",
        "# estimate the normals\n",
        "normals = normal_estimation(pts, k=16)\n",
        "\n",
        "# compute the best plane\n",
        "plane = plane_from_one_point_normal(pts, normals)\n",
        "\n",
        "# get the inliers\n",
        "mask = get_inliers_in_plane_normals(normals, plane, 0.95)\n",
        "\n",
        "# give red color to the inliers\n",
        "cols_plane_tmp = cols[mask].copy()\n",
        "cols_plane_tmp *= 0\n",
        "cols_plane_tmp[:,0] = 255\n",
        "cols_plane = cols.copy()\n",
        "cols_plane[mask] = cols_plane_tmp\n",
        "\n",
        "# display the point cloud\n",
        "point_cloud_visu(pts,cols_plane)"
      ],
      "metadata": {
        "id": "kBgno0FLQiLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need also to use a different function to compute the number of iterations, as we are now picking only one point to generate the hypothesis.\n",
        "\n",
        "**Question:** fill `get_max_num_iter_normal` to compute the number of iterations"
      ],
      "metadata": {
        "id": "00t2aZY0jjTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_num_iter_normal(min_pts, num_pts, proba_of_success):\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  T = 10\n",
        "  return int(T) + 1"
      ],
      "metadata": {
        "id": "bDJVK1PAjPLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Finally, we can use the RANSAC algorithm with this plane selector.\n",
        "\n",
        "**Question:** fill `search_one_plane_normals`."
      ],
      "metadata": {
        "id": "uj7sgb0GQoke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSAC loop\n",
        "def search_one_plane_normals(pts, normals, min_pts, plane_threshold, orient_threshold, proba_of_success):\n",
        "  \"\"\"\n",
        "  Function: search the best plane by iteratively selecting plane hypotheses and\n",
        "  retain the plane with the most inliers\n",
        "  - input:\n",
        "    - pts: the point cloud\n",
        "    - min_pts: minimal number of points in a valid shape\n",
        "    - plane_threshold: the distance threshold for plane hypothesis\n",
        "    - orient_threshold: the minimal scalar product of the normals to be\n",
        "        to be considered an inlier\n",
        "  - output:\n",
        "    - plane_equation: equation of the plane\n",
        "    - inlier_mask: boolean mask for the inliers\n",
        "  \"\"\"\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "  # use both masks on distance and normals\n",
        "  ##################\n",
        "\n",
        "  # to be removed\n",
        "  cur_plane_equation = np.array([1,0,0,0])\n",
        "  cur_plane_mask = np.ones(pts.shape[0], dtype=bool)\n",
        "\n",
        "  return cur_plane_equation, cur_plane_mask\n",
        "\n",
        "# load the point cloud\n",
        "pts, cols = load_and_decimate_room_pc_voxels()\n",
        "\n",
        "# estimate normals\n",
        "normals = normal_estimation(pts, k=16)\n",
        "\n",
        "# search the best plane\n",
        "plane_equation, plane_mask = search_one_plane_normals(pts, normals,\n",
        "  min_pts=500,\n",
        "  plane_threshold=0.05,\n",
        "  orient_threshold=0.95,\n",
        "  proba_of_success=0.999)\n",
        "\n",
        "# give red color to the inliers\n",
        "cols_plane_tmp = cols[plane_mask].copy()\n",
        "cols_plane_tmp *= 0\n",
        "cols_plane_tmp[:,0] = 255\n",
        "cols_plane = cols.copy()\n",
        "cols_plane[plane_mask] = cols_plane_tmp\n",
        "\n",
        "# display the point cloud\n",
        "point_cloud_visu(pts,cols_plane)\n"
      ],
      "metadata": {
        "id": "L1jKN8L-qgWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-plane RANSAC\n",
        "\n",
        "In the previous sections, we search for one plane.\n",
        "In practice, we usually want to extract multiple planes in a given scene.\n",
        "We now implement the function that search for planes until no plane (containing a minimal amount of points can be found).\n",
        "\n",
        "**Question:** implement the `ransac` function.\n",
        "\n",
        "*Note 1:* the process is iterative:\n",
        "- it finds one plane\n",
        "- it removes the inliers from the point cloud\n",
        "- it iterate the process\n",
        "\n",
        "*Note 2:* as the process go on the size of the point cloud decreases, thus the number of iterations needed also decreases."
      ],
      "metadata": {
        "id": "WpsG1oQoPws4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSAC loop multi plane\n",
        "\n",
        "def ransac(pts_, normals_, min_pts,\n",
        "           plane_search_function,\n",
        "           plane_search_function_args):\n",
        "\n",
        "  pts = pts_.copy()\n",
        "  normals = normals_.copy()\n",
        "\n",
        "\n",
        "  ##################\n",
        "  ### Fill this part\n",
        "  ##################\n",
        "\n",
        "  shapes = [\n",
        "      pts[:10],\n",
        "      pts[10:20],\n",
        "  ]\n",
        "\n",
        "  return shapes\n",
        "\n",
        "# load the point cloud\n",
        "pts, cols = load_and_decimate_room_pc_voxels()\n",
        "\n",
        "# compute the normals\n",
        "normals = normal_estimation(pts, k=16)\n",
        "\n",
        "# ransac\n",
        "shapes = ransac(pts, normals,\n",
        "                min_pts=200,\n",
        "                plane_search_function=search_one_plane_normals,\n",
        "                plane_search_function_args=dict(\n",
        "                    plane_threshold=0.05,\n",
        "                    orient_threshold=0.9,\n",
        "                    proba_of_success=0.999\n",
        "                ))\n",
        "\n",
        "# visu, with one random color for each shape\n",
        "shape_colors = []\n",
        "for shape_pts in shapes:\n",
        "  color = np.random.randint(0,255,size=(1,3))\n",
        "  color = np.repeat(color, shape_pts.shape[0], axis=0)\n",
        "  shape_colors.append(color)\n",
        "shapes_cat = np.concatenate(shapes, axis=0)\n",
        "shape_colors_cat = np.concatenate(shape_colors, axis=0)\n",
        "\n",
        "point_cloud_visu(shapes_cat, shape_colors_cat)"
      ],
      "metadata": {
        "id": "1APV95tsOorK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliography\n",
        "\n",
        "[1] Hoppe, Hugues, et al. \"Surface reconstruction from unorganized points.\" Proceedings of the 19th annual conference on computer graphics and interactive techniques. 1992.\n",
        "\n",
        "[2] Schnabel, Ruwen, Roland Wahl, and Reinhard Klein. \"Efficient RANSAC for point‐cloud shape detection.\" Computer graphics forum. Vol. 26. No. 2. Oxford, UK: Blackwell Publishing Ltd, 2007."
      ],
      "metadata": {
        "id": "oON30G6cfrQl"
      }
    }
  ]
}